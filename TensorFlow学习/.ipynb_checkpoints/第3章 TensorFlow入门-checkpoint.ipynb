{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章 TensorFlow入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 TensorFlow 计算模型——计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 计算图的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1.0, 2.0], name='a')\n",
    "b = tf.constant([2.0, 3.0], name='b')\n",
    "result = a + b\n",
    "# 直接新建的常量和变量会在默认图中\n",
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# 可以新建计算图\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.zeros_initializer())\n",
    "    \n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.ones_initializer())\n",
    "\n",
    "# 计算图之间的张量和计算是隔离开的\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        \n",
    "with tf.Session(graph=g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 TensorFLow数据模型——张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 在tensorflow中张量只是对计算结果的引用，在张量中没有真正保存数字，而是保存的如何得到这些数字的计算过程\n",
    "# 如一下代码中，向量加法不会得到结果，而会得到结果的一个引用\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1.0, 2.0], name='a')\n",
    "b = tf.constant([2.0, 3.0], name='b')\n",
    "result = tf.add(a, b, name='add')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor(\"add:0\", shape=(2,), dtype=float32)  \n",
    "张量有三个属性:name, shape, type  \n",
    "**name**: 是张量的唯一标识符，如果张量是计算节点输出的结果，张量的命名方式就为node:src_ouput的形式。其中node为节点名称，src_souput表示当前张量是来自节点的第几个输出，上面的“add:0”就说明了result这个张量是节点add的第一个输出结果(编号从0开始)  \n",
    "**shape**: 是用来描述张量的维度信息，同numpy  \n",
    "**type**: 是张量的数据类型，没一个张量会有一个唯一的类型。TensorFlow会对所有参与运算的张量进行类型检查  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 TensorFlow运行模型——会话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会话是用来管理TensorFlow程序运行时所有资源，计算完成后需要关闭会话来帮组系统回收资源\n",
    "# 使用会话的两种方式\n",
    "# 第一种方式需要手动释放资源\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1.0, 2.0], name='a', dtype='float32')\n",
    "b = tf.constant([2.0, 3.0], name='b', dtype='float32')\n",
    "result = tf.add(a, b, name='add')\n",
    "sess = tf.Session()\n",
    "sess.run(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二种方式是使用python的上下文管理器\n",
    "# 上下文管理器会自动释放资源\n",
    "# 上下文管理器内的代码才能使用上下文管理器提供的变量\n",
    "with tf.Session() as sess:\n",
    "    sess.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "# 通过默认会话计算张量的取值\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(result.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "# 以下代码也可以完成张量取值的功能\n",
    "with tf.Session() as sess:\n",
    "    sess.run(result)\n",
    "    print(result.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow提供了一种在交互环境下直接构建默认绘画的函数，tf.InteractiveSession，使用这个函数会自动将生成的会话注册到默认会话下\n",
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0], name='a', dtype='float32')\n",
    "b = tf.constant([2.0, 3.0], name='b', dtype='float32')\n",
    "result = tf.add(a, b, name='add')\n",
    "sess = tf.InteractiveSession()\n",
    "print(result.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 TensorFlow实现神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578]]\n"
     ]
    }
   ],
   "source": [
    "# 一个简单的前向传播的例子\n",
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1, seed=1)) # 似乎可以用元组和列表的形式来表达向量的形状\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1, seed=1))\n",
    "\n",
    "x = tf.constant([[0.7, 0.9]])\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(w1.initializer)\n",
    "sess.run(w2.initializer)\n",
    "\n",
    "print(sess.run(y))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8544476]]\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow提供了placeholder来方便数据输入网络，而不用产生大量的常量\n",
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1))\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1))\n",
    "\n",
    "# 定义placeholder作为存放数据的地方，类型是必须要定义的，维度可以不定义，但是维度确定可以减少出错的概率\n",
    "x = tf.placeholder(tf.float32, shape=(1, 2), name='input')\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "print(sess.run(y, feed_dict={x: [[0.7, 0.9]]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4373758 ]\n",
      " [0.14375882]\n",
      " [0.9910452 ]\n",
      " [0.86997384]]\n"
     ]
    }
   ],
   "source": [
    "# placeholder对batch的数据也能很好的支持\n",
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1))\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1))\n",
    "\n",
    "# 定义placeholder作为存放数据的地方，类型是必须要定义的，维度可以不定义，但是维度确定可以减少出错的概率\n",
    "# 为了方便batch计算，批量的维度可以定义为None，让其自适应\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='input')\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "print(sess.run(y, feed_dict={x: [[0.7, 0.9], [0.1, 0.4], [0.5, 0.8], [0.4, 0.3]]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow反向传播\n",
    "\n",
    "y = tf.sigmoid(y)\n",
    "cross_entropy = -tf.reduce_mean(y * tf.log(tf.clip_by_value(y, 1e-10, 1.0))\n",
    "                                + (1 - y) * tf.log(tf.clip_by_value((1 - y), 1e-10, 1.0)))\n",
    "learning_rate = 0.001\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy) # 反向传播优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "placeholder() got multiple values for argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a2ea1f8b3703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x-input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y-input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: placeholder() got multiple values for argument 'dtype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "y = tf.sigmoid(y)\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)) +\n",
    "                               (1 - y_) * tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = np.random.RandomState(1)\n",
    "datasets_size = 128\n",
    "X = rdm.rand(datasets_size, 2)\n",
    "Y = [[int(x1 + x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    \n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % datasets_size\n",
    "        end = min(start+batch_size, datasets_size)\n",
    "        \n",
    "        sess.run(train_step, feed_dict={x: X[start: end], y_: Y[start: end]})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y: Y})\n",
    "            print('After {} training step(2), cross entropy on all data is {}'.format(i, total_cross_entropy))\n",
    "            \n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
